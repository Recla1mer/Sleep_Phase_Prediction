{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File: dataset_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autoreload extension allows you to tweak the code in the imported modules\n",
    "# and rerun cells to reflect the changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we demonstrate the implemented class that helps you to manage training data and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One file can only be accessed by one class at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shhs_data_manager = DataManager(file_path = \"messing_around.pkl\")\n",
    "shhs_data_manager = DataManager(file_path = \"messing_around.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the implemented functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import random\n",
    "import h5py # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you can check whether the implemented functions in this project work correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling number of datapoints from signal- to target- frequency:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would highly suggest to provide data where the signals don't need to be scaled to the frequencies of the data\n",
    "used to train the neural network.\n",
    "\n",
    "If there is no other option, then so be it. Here is a demonstration of the functions that will be applied to \n",
    "your data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Classification Frequency: 0.05 -> Target Frequency: 0.03333333333333333\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Classification array:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "Classification array shape:  (15,)\n",
      "\n",
      "Scaled array:  [ 0  1  3  4  6  7  9 10 12 13]\n",
      "Scaled array shape:  (10,)\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Classification Frequency: 0.02 -> Target Frequency: 0.03333333333333333\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Classification array:  [0 1 2 3 4 5 6 7 8]\n",
      "Classification array shape:  (9,)\n",
      "\n",
      "Scaled array:  [0 1 1 2 2 3 4 4 5 5 6 7 7 8 8]\n",
      "Scaled array shape:  (15,)\n"
     ]
    }
   ],
   "source": [
    "classification_array = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "classification_frequency = 1/20\n",
    "target_frequency = 1/30\n",
    "\n",
    "print(\"-\"*71)\n",
    "print(f\"Classification Frequency: {classification_frequency} -> Target Frequency: {target_frequency}\")\n",
    "print(\"-\"*71)\n",
    "print(\"\\nClassification array: \", classification_array)\n",
    "print(\"Classification array shape: \", classification_array.shape)\n",
    "\n",
    "reshaped_array = scale_classification_signal(\n",
    "        signal = classification_array, \n",
    "        signal_frequency = classification_frequency,\n",
    "        target_frequency = target_frequency\n",
    "        )\n",
    "\n",
    "print(\"\\nScaled array: \", reshaped_array)\n",
    "print(\"Scaled array shape: \", reshaped_array.shape)\n",
    "\n",
    "classification_array = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "classification_frequency = 1/50\n",
    "target_frequency = 1/30\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-\"*71)\n",
    "print(f\"Classification Frequency: {classification_frequency} -> Target Frequency: {target_frequency}\")\n",
    "print(\"-\"*71)\n",
    "print(\"\\nClassification array: \", classification_array)\n",
    "print(\"Classification array shape: \", classification_array.shape)\n",
    "\n",
    "reshaped_array = scale_classification_signal(\n",
    "        signal = classification_array, \n",
    "        signal_frequency = classification_frequency,\n",
    "        target_frequency = target_frequency\n",
    "        )\n",
    "\n",
    "print(\"\\nScaled array: \", reshaped_array)\n",
    "print(\"Scaled array shape: \", reshaped_array.shape)\n",
    "\n",
    "del reshaped_array, classification_array, classification_frequency, target_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Continuous Frequency: 3 -> Target Frequency: 4\n",
      "---------------------------------------------------------------------------\n",
      "Continuous array: [0 1 2 3 4 5] / [0. 1. 2. 3. 4. 5.]\n",
      "Continuous array shape:  (6,)\n",
      "\n",
      "Scaled array: [0 1 2 2 3 4 4 5] / [0.   0.75 1.5  2.25 3.   3.75 4.5  5.  ]\n",
      "Scaled array shape:  (8,)\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Continuous Frequency: 5 -> Target Frequency: 4\n",
      "---------------------------------------------------------------------------\n",
      "Continuous array: [0 1 2 3 4 5 6 7 8 9] / [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "Continuous array shape:  (10,)\n",
      "\n",
      "Scaled array: [0 1 2 4 5 6 8 9] / [0.   1.25 2.5  3.75 5.   6.25 7.5  8.75]\n",
      "Scaled array shape:  (8,)\n"
     ]
    }
   ],
   "source": [
    "continuous_array_int = np.array([0, 1, 2, 3, 4, 5])\n",
    "continuous_array_float = np.array([0, 1, 2, 3, 4, 5], dtype = float)\n",
    "continuous_frequency = 3\n",
    "target_frequency = 4\n",
    "\n",
    "print(\"-\"*75)\n",
    "print(f\"Continuous Frequency: {continuous_frequency} -> Target Frequency: {target_frequency}\")\n",
    "print(\"-\"*75)\n",
    "print(f\"Continuous array: {continuous_array_int} / {continuous_array_float}\")\n",
    "print(\"Continuous array shape: \", continuous_array_int.shape)\n",
    "\n",
    "reshaped_array_int = interpolate_signal(\n",
    "        signal = continuous_array_int, \n",
    "        signal_frequency = continuous_frequency,\n",
    "        target_frequency = target_frequency\n",
    "        )\n",
    "\n",
    "reshaped_array_float = interpolate_signal(\n",
    "        signal = continuous_array_float, \n",
    "        signal_frequency = continuous_frequency,\n",
    "        target_frequency = target_frequency\n",
    "        )\n",
    "\n",
    "print(f\"\\nScaled array: {reshaped_array_int} / {reshaped_array_float}\")\n",
    "print(\"Scaled array shape: \", reshaped_array_int.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "continuous_array_int = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "continuous_array_float = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype = float)\n",
    "continuous_frequency = 5\n",
    "target_frequency = 4\n",
    "\n",
    "print(\"-\"*75)\n",
    "print(f\"Continuous Frequency: {continuous_frequency} -> Target Frequency: {target_frequency}\")\n",
    "print(\"-\"*75)\n",
    "print(f\"Continuous array: {continuous_array_int} / {continuous_array_float}\")\n",
    "print(\"Continuous array shape: \", continuous_array_int.shape)\n",
    "\n",
    "reshaped_array_int = interpolate_signal(\n",
    "        signal = continuous_array_int, \n",
    "        signal_frequency = continuous_frequency,\n",
    "        target_frequency = target_frequency\n",
    "        )\n",
    "\n",
    "reshaped_array_float = interpolate_signal(\n",
    "        signal = continuous_array_float, \n",
    "        signal_frequency = continuous_frequency,\n",
    "        target_frequency = target_frequency\n",
    "        )\n",
    "\n",
    "print(f\"\\nScaled array: {reshaped_array_int} / {reshaped_array_float}\")\n",
    "print(\"Scaled array shape: \", reshaped_array_int.shape)\n",
    "\n",
    "del reshaped_array_int, reshaped_array_float, continuous_array_int, continuous_array_float, continuous_frequency, target_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting a signal which is too long for the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A signal which is too short will be padded with zeros. No big deal. On the other hand: A signal which is too \n",
    "long will be splitted into multiple signals. To create more data, the 10 hour range will be shifted along the\n",
    "signal.\n",
    "\n",
    "This shift should not be too small, to create redundant data but also not too big, because the more data the \n",
    "better. So we try to find a shift size close to 1 hour, which lets us shift an integer amount of times\n",
    "easily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding optimal shift size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal shift length for signal which is 2.5 hours longer than desired length of 10 hours: 0.833 hours\n"
     ]
    }
   ],
   "source": [
    "signal_length_addition_hours = 2.5\n",
    "desired_length_hours = 10\n",
    "\n",
    "optimal_shift_length = calculate_optimal_shift_length(\n",
    "        signal_length = (desired_length_hours + signal_length_addition_hours) * 3600, # type: ignore\n",
    "        desired_length = desired_length_hours*3600, \n",
    "        wanted_shift_length = 3600,\n",
    "        absolute_shift_deviation = 1800,\n",
    ")\n",
    "\n",
    "print(f\"Optimal shift length for signal which is {signal_length_addition_hours} hours longer than desired length of {desired_length_hours} hours: {round(optimal_shift_length/3600, 3)} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function to find optimal shift length is embedded in the following split funtion. The optimal\n",
    "shift size will be estimated for every signal individually.\n",
    "\n",
    "If there is no integer shift size in range, that lets you shift the signal so, that you perfectly enclose the\n",
    "last datapoints of the long signal, then the last shift will be altered so that it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift length: 15120\n",
      "Shift length: 3780.0 seconds\n",
      "Signal shape:  (174240,)\n",
      "Datapoints in NN: 144000\n",
      "Signals from splitting shape:  (3, 144000)\n"
     ]
    }
   ],
   "source": [
    "# Create random signal\n",
    "frequency = 4\n",
    "length_signal_seconds = 12.1 * 3600\n",
    "signal = np.random.rand(int(length_signal_seconds * frequency))\n",
    "\n",
    "# Only important parameters here:\n",
    "nn_signal_seconds = 10 * 3600\n",
    "shift_length_seconds = 3600\n",
    "absolute_shift_deviation_seconds = 1800\n",
    "\n",
    "signals_from_splitting, shift_length = split_long_signal(\n",
    "        signal = signal, \n",
    "        sampling_frequency = frequency,\n",
    "        target_frequency = frequency,\n",
    "        signal_type = \"feature\",\n",
    "        nn_signal_duration_seconds = nn_signal_seconds,\n",
    "        wanted_shift_length_seconds = shift_length_seconds,\n",
    "        absolute_shift_deviation_seconds = absolute_shift_deviation_seconds\n",
    "        )\n",
    "\n",
    "print(\"Shift length:\", shift_length)\n",
    "print(f\"Shift length: {shift_length / frequency} seconds\")\n",
    "print(\"Signal shape: \", signal.shape)\n",
    "print(f\"Datapoints in NN: {nn_signal_seconds * frequency}\")\n",
    "print(\"Signals from splitting shape: \", signals_from_splitting.shape)\n",
    "\n",
    "del signals_from_splitting, signal, shift_length, frequency, nn_signal_seconds, shift_length_seconds, absolute_shift_deviation_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting signals within dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random signal\n",
    "frequency = 4\n",
    "length_signal_seconds = 12.1 * 3600\n",
    "signal = np.random.rand(int(length_signal_seconds * frequency))\n",
    "\n",
    "# Only important parameters here:\n",
    "nn_signal_seconds = 10 * 3600\n",
    "shift_length_seconds = 3600\n",
    "absolute_shift_deviation_seconds = 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a .h5 - file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the available training datasets for our neural network model are stored in a .h5 file. So we need\n",
    "to be able to read it. These are the important operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random patient: 201558_1\n",
      "[0 1 2 3 5]\n",
      "\n",
      "key: slp\n",
      "Data shape: (1039,)\n",
      "Data frequency: 0.03333333333333333\n",
      "Inverse data frequency: 30.0\n",
      "Data length: 31170.0 s\n",
      "\n",
      "key: rri\n",
      "Data shape: (124680,)\n",
      "Data frequency: 4\n",
      "Inverse data frequency: 0.25\n",
      "Data length: 31170.0 s\n"
     ]
    }
   ],
   "source": [
    "shhs_dataset = h5py.File(\"../Training_Data/SHHS_dataset.h5\", 'r')\n",
    "patients = list(shhs_dataset['slp'].keys()) # type: ignore\n",
    "\n",
    "random_patient = patients[np.random.randint(0, len(patients))]\n",
    "print(f\"Random patient: {random_patient}\")\n",
    "\n",
    "print(np.unique(shhs_dataset[\"slp\"][random_patient][:])) # type: ignore\n",
    "\n",
    "for key in [\"slp\", \"rri\"]:\n",
    "    print(f\"\\nkey: {key}\")\n",
    "\n",
    "    patient_data = shhs_dataset[key][random_patient][:] # type: ignore\n",
    "    print(f\"Data shape: {patient_data.shape}\") # type: ignore\n",
    "\n",
    "    data_freq = shhs_dataset[key].attrs[\"freq\"] # type: ignore\n",
    "    print(f\"Data frequency: {data_freq}\")\n",
    "    print(f\"Inverse data frequency: {1/data_freq}\") # type: ignore\n",
    "\n",
    "    print(f\"Data length: {patient_data.shape[0]/data_freq} s\") # type: ignore\n",
    "\n",
    "del shhs_dataset, patients, random_patient, key, patient_data, data_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide up a signal into overlapping windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hardest thing about this is, that 'window_overlap' and 'datapoints_per_window' must be chosen so that\n",
    "the whole signal fits perfectly into n windows. \n",
    "\n",
    "Additionally, those values must be integers. This means that 'window_duration_seconds' and 'overlap_seconds'\n",
    "multiplied with 'target_fequency' as well as 'sampling_frequency' must be integers. (The features and the target labels\n",
    "must fit equally well into the windows, so that we can find the correlation between a feature- and target- window.)\n",
    "\n",
    "We have the RRI and MAD values as features and the sleep phase as target classification. As we will see,\n",
    "RRI and MAD values were recorded with an integer sampling frequency. While the sampling frequency of the \n",
    "sleep classification is 1/30. \n",
    "\n",
    "Finding window parameters that fullfill the conditions mentioned is easier than it sounds. We will always pass data\n",
    "to the neural network that is 10 hours long. Now, we just need to think in seconds and find integer values\n",
    "for 'window_duration_seconds' and 'overlap_seconds' that are a multiple of 30:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding optimal window_parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suitable window parameters for signal of length: 36000:\n",
      "-------------------------------------------------------\n",
      "Number of windows: 1025, Window size: 160, Overlap: 125.0\n",
      "Number of windows: 1026, Window size: 125, Overlap: 90.0\n",
      "Number of windows: 1055, Window size: 164, Overlap: 130.0\n",
      "Number of windows: 1056, Window size: 130, Overlap: 96.0\n",
      "Number of windows: 1087, Window size: 162, Overlap: 129.0\n",
      "Number of windows: 1088, Window size: 129, Overlap: 96.0\n",
      "Number of windows: 1121, Window size: 160, Overlap: 128.0\n",
      "Number of windows: 1122, Window size: 128, Overlap: 96.0\n",
      "Number of windows: 1157, Window size: 164, Overlap: 133.0\n",
      "Number of windows: 1158, Window size: 133, Overlap: 102.0\n",
      "Number of windows: 1196, Window size: 150, Overlap: 120.0\n",
      "Number of windows: 1197, Window size: 120, Overlap: 90.0\n"
     ]
    }
   ],
   "source": [
    "find_suitable_window_parameters(\n",
    "        signal_length = 10 * 3600,\n",
    "        number_windows_range = (1000, 1400),\n",
    "        window_size_range = (120, 180),\n",
    "        minimum_window_size_overlap_difference = 30\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our options are:\n",
    "\n",
    "Number of windows: 1196, Window size: 150, Overlap: 120.0 \\\n",
    "Number of windows: 1197, Window size: 120, Overlap: 90.0\n",
    "\n",
    "We will choose the latter, because we don't want the window_size to be too large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When transforming a classification signal into windows, which is supposed to be the target in the neural \n",
    "network, then each window will only be represented by the most common sleep stage. If there is a tie\n",
    "between the labels, then the one with the highest priority will be chosen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (1200,)\n",
      "Signal in windows shape: (1197,)\n"
     ]
    }
   ],
   "source": [
    "signal_length_seconds = 10 * 3600\n",
    "frequency = 1/30\n",
    "signal_length = int(signal_length_seconds * frequency)\n",
    "\n",
    "signal = np.array([random.randint(0, 5) for _ in range(signal_length)])\n",
    "\n",
    "signal_in_windows = signal_to_windows(\n",
    "    signal = signal, # type: ignore\n",
    "    datapoints_per_window = int(120 * frequency),\n",
    "    window_overlap = int(90 * frequency),\n",
    "    signal_type = \"target\",\n",
    "    priority_order=[0, 1, 2, 3, 4, 5]\n",
    "    )\n",
    "\n",
    "print(f\"Signal shape: {signal.shape}\")\n",
    "print(f\"Signal in windows shape: {signal_in_windows.shape}\")\n",
    "\n",
    "del signal, signal_in_windows, signal_length_seconds, frequency, signal_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (36000,)\n",
      "Signal in windows shape: (1197, 120)\n"
     ]
    }
   ],
   "source": [
    "signal = np.random.rand(36000)\n",
    "\n",
    "signal_in_windows = signal_to_windows(\n",
    "    signal = signal, # type: ignore\n",
    "    datapoints_per_window = 120,\n",
    "    window_overlap = 90,\n",
    "    signal_type = \"feature\"\n",
    "    )\n",
    "\n",
    "print(f\"Signal shape: {signal.shape}\")\n",
    "print(f\"Signal in windows shape: {signal_in_windows.shape}\")\n",
    "\n",
    "del signal, signal_in_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will actually be applied the transform a signal into windows. It will make sure\n",
    "that the data is passed correctly to the function mentioned above. \n",
    "\n",
    "This means it will:\n",
    "- correct freuqency of signal if needed\n",
    "- check if 'number_nn_datapoints', 'datapoints_per_window' and 'window_overlap' are integers\n",
    "- check if 'datapoints_per_window' and 'window_overlap' perfectly fit into 'number_nn_datapoints'\n",
    "- compare length of provided signal to length of signal in nn ('number_nn_datapoints')\n",
    "    - if smaller: Pad with Zeros\n",
    "    - if bigger: Print warning, but continue by cropping last datapoints\n",
    "- check if signal transformed to windows has the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random array shape: (36000,)\n",
      "Reshaped array shape: (1197, 480)\n",
      "Random array shape: (1200,)\n",
      "Reshaped array shape: (1197,)\n"
     ]
    }
   ],
   "source": [
    "random_array = np.random.rand(36000)\n",
    "reshaped_array = reshape_signal(\n",
    "    signal = random_array, # type: ignore\n",
    "    sampling_frequency = 1,\n",
    "    target_frequency = 4, \n",
    "    number_windows = 1197, \n",
    "    window_duration_seconds = 120, \n",
    "    overlap_seconds = 90,\n",
    "    signal_type = \"feature\",\n",
    "    nn_signal_duration_seconds = 10*3600,\n",
    "    )\n",
    "\n",
    "print(f\"Random array shape: {random_array.shape}\")\n",
    "print(f\"Reshaped array shape: {reshaped_array.shape}\")\n",
    "\n",
    "random_array = np.array([random.randint(0, 5) for _ in range(int(36000/30))])\n",
    "reshaped_array = reshape_signal(\n",
    "    signal = random_array, # type: ignore\n",
    "    sampling_frequency = 1/30,\n",
    "    target_frequency = 1/30, \n",
    "    number_windows = 1197, \n",
    "    window_duration_seconds = 120, \n",
    "    overlap_seconds = 90,\n",
    "    signal_type = \"target\",\n",
    "    nn_signal_duration_seconds = 10*3600,\n",
    "    )\n",
    "\n",
    "print(f\"Random array shape: {random_array.shape}\")\n",
    "print(f\"Reshaped array shape: {reshaped_array.shape}\")\n",
    "\n",
    "del random_array, reshaped_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change what is padded depending on target and feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
