{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** *Johannes Peter Knoll*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Within this notebook you will:\n",
    "- Preprocess raw data\n",
    "- Train Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autoreload extension allows you to tweak the code in the imported modules\n",
    "# and rerun cells to reflect the changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL IMPORTS\n",
    "from dataset_processing import *\n",
    "from neural_network_model import *\n",
    "\n",
    "# IMPORTS\n",
    "import numpy as np # type: ignore\n",
    "import random\n",
    "import h5py # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Dataset for Neural Network\n",
    "\n",
    "The class SleepDataManager handles the data we want to pass to the network. It makes the data accessible in\n",
    "a memory saving way, but needs to save it (again) into a pickle file. Of course, you can delete the .h5\n",
    "file afterwards if you want to.\n",
    "\n",
    "We unfortunately have multiple sources (besides the SHHS Dataset) with data that we can train the network on.\n",
    "We need to make sure that the data is uniform in sampling frequency, signal length, etc., which is why we will\n",
    "check and transform each datapoint before (and afterwards saving it) using the SleepDataManager class.\n",
    "\n",
    "During the saving process, the SleepDataManager makes sure that the data is uniform in every way and might\n",
    "perform following actions:\n",
    "- Scale number of datapoints in signal if sampling frequency does not match\n",
    "- Alter sleep stage labels if they do not refer to the same context\n",
    "- Split datapoint into multiple if signal duration is longer than required for the neural network\n",
    "\n",
    "To do all of this, we need to provide more information than the signal itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saveable Datapoint:\n",
    "\"\"\"\n",
    "{\n",
    "    \"ID\": str,                  # always required\n",
    "    \"RRI\": np.ndarray,\n",
    "    \"MAD\": np.ndarray,\n",
    "    \"SLP\": np.ndarray,\n",
    "    \"RRI_frequency\": int,       # required if RRI signal is provided\n",
    "    \"MAD_frequency\": int,       # required if MAD signal is provided\n",
    "    \"SLP_frequency\": int,       # required if SLP signal is provided\n",
    "    \"sleep_stage_label\": list   # required if SLP signal is provided\n",
    "} \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the keys are save explaining, except for the last one:\n",
    "\n",
    "We want to assign different sleep stage labels in our network (SSM in the following):\n",
    "\n",
    "|number|SHHS stage|GIF stage|SSM stage|\n",
    "|------|----------|---------|---------|\n",
    "|  0   | wake     |         | wake    |\n",
    "|  1   | N1       |         | LS      |\n",
    "|  2   | N2       |         | DS      |\n",
    "|  3   | N3       |         | REM     |\n",
    "|  5   | REM      |         |         |\n",
    "| other| artifact |         |         |\n",
    "| -1   |          |         | artifact|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see: N1 needs to be classified as wake, N2 as LS (light sleep), and N3 as DS (deep sleep).\n",
    "To do this, we effectively need to change: \\\n",
    "0 -> 0, 1 -> 0, 2 -> 1, 3 -> 2, 5 -> 3, other -> -1\n",
    "\n",
    "To make this achievable by the algorithm, we just need to say which labels correspond to which stage\n",
    "in the \"sleep_stage_label\" key as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shhs_sleep_stage_label = {\"wake\": [0, 1], \"LS\": [2], \"DS\": [3], \"REM\": [5], \"artifect\": [\"other\"]}\n",
    "gif_sleep_stage_label = {\"wake\": [0, 1], \"LS\": [2], \"DS\": [3], \"REM\": [5], \"artifect\": [\"other\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHHS Dataset\n",
    "\n",
    "The [Sleep Heart Health Study (SHHS)](https://sleepdata.org/datasets/shhs) is a multi-center cohort study implemented by the National Heart Lung & Blood Institute to determine the cardiovascular and other consequences of sleep-disordered breathing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://onedrive.live.com/download?cid=45D5A10F94E33861&resid=45D5A10F94E33861%21248707&authkey=AKRa5kb3XFj4G-o\" -O shhs_dataset.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_shhs_dataset = \"../Training_Data/SHHS_dataset.h5\"\n",
    "path_to_shhs_dataset = \"Raw_Data/SHHS_dataset.h5\"\n",
    "\n",
    "shhs_dataset = h5py.File(path_to_shhs_dataset, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering Data from .h5 into .pkl file using SleepDataManager\n",
    "\n",
    "It is wise to check if all ID's are unique prior to saving. Then we can skip\n",
    "checking every ID in the database when saving each datapoint, which will speed up the saving process greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# initializing the database\n",
    "path_to_save_processed_shhs_data = \"Processed_Data/shhs_data.pkl\"\n",
    "shhs_data_manager = SleepDataManager(file_path = path_to_save_processed_shhs_data)\n",
    "\n",
    "# accessing patient ids:\n",
    "patients = list(shhs_dataset['slp'].keys()) # type: ignore\n",
    "\n",
    "# check if patient ids are unique:\n",
    "shhs_data_manager.check_if_ids_are_unique(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all ID's are unique, you can continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all data from SHHS dataset to the shhs_data.pkl file\n",
    "for patient_id in patients:\n",
    "    new_datapoint = {\n",
    "        \"ID\": patient_id,\n",
    "        \"RRI\": shhs_dataset[\"rri\"][patient_id][:], # type: ignore\n",
    "        \"SLP\": shhs_dataset[\"slp\"][patient_id][:], # type: ignore\n",
    "        \"RRI_frequency\": shhs_dataset[\"rri\"].attrs[\"freq\"], # type: ignore\n",
    "        \"SLP_frequency\": shhs_dataset[\"slp\"].attrs[\"freq\"], # type: ignore\n",
    "        \"sleep_stage_label\": copy.deepcopy(shhs_sleep_stage_label)\n",
    "    }\n",
    "\n",
    "    shhs_data_manager.save(new_datapoint, unique_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data to overlapping windows\n",
    "\n",
    "We want to pass the signal in overlapping windows to the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshhs_data_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_signals_to_windows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_windows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1197\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_duration_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverlap_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpriority_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Sleep_Phase_Prediction/dataset_processing.py:1705\u001b[0m, in \u001b[0;36mSleepDataManager.transform_signals_to_windows\u001b[0;34m(self, number_windows, window_duration_seconds, overlap_seconds, priority_order)\u001b[0m\n\u001b[1;32m   1702\u001b[0m     this_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_target_with\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m signal_key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSLP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_feature_with\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m signal_key \u001b[38;5;129;01min\u001b[39;00m data_point:\n\u001b[0;32m-> 1705\u001b[0m         data_point[window_key] \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_signal_to_overlapping_windows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m            \u001b[49m\u001b[43msignal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_point\u001b[49m\u001b[43m[\u001b[49m\u001b[43msignal_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m            \u001b[49m\u001b[43msampling_frequency\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43msignal_frequency_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_frequency\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43msignal_frequency_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnn_signal_duration_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msignal_length_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpad_with\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthis_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnumber_windows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumber_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwindow_duration_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_duration_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverlap_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moverlap_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m            \u001b[49m\u001b[43msignal_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthis_signal_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpriority_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpriority_order\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;66;03m# Append data point to the working file\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m append_to_pickle(data \u001b[38;5;241m=\u001b[39m data_point, file_name \u001b[38;5;241m=\u001b[39m working_file_path)\n",
      "File \u001b[0;32m~/Desktop/Sleep_Phase_Prediction/dataset_processing.py:769\u001b[0m, in \u001b[0;36mreshape_signal_to_overlapping_windows\u001b[0;34m(signal, sampling_frequency, target_frequency, nn_signal_duration_seconds, pad_with, number_windows, window_duration_seconds, overlap_seconds, signal_type, priority_order)\u001b[0m\n\u001b[1;32m    766\u001b[0m signal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(signal, [pad_with \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_missing_datapoints)]) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;66;03m# Reshape signal to windows\u001b[39;00m\n\u001b[0;32m--> 769\u001b[0m signal_windows \u001b[38;5;241m=\u001b[39m \u001b[43msignal_to_windows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatapoints_per_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatapoints_per_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_overlap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_overlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignal_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msignal_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpriority_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpriority_order\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# check if signal_windows has the correct shape\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signal_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Sleep_Phase_Prediction/dataset_processing.py:632\u001b[0m, in \u001b[0;36msignal_to_windows\u001b[0;34m(signal, datapoints_per_window, window_overlap, signal_type, priority_order)\u001b[0m\n\u001b[1;32m    629\u001b[0m this_window \u001b[38;5;241m=\u001b[39m signal[i:i\u001b[38;5;241m+\u001b[39mdatapoints_per_window]\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signal_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 632\u001b[0m     windows \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mthis_window\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m signal_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# collect unique labels and their counts\u001b[39;00m\n\u001b[1;32m    636\u001b[0m     different_labels, label_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(this_window, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/master/lib/python3.12/site-packages/numpy/lib/function_base.py:5618\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5616\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5617\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shhs_data_manager.transform_signals_to_windows(\n",
    "    number_windows = 1197, \n",
    "    window_duration_seconds = 120, \n",
    "    overlap_seconds = 90, \n",
    "    priority_order = [0, 1, 2, 3, 5, -1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIF Dataset\n",
    "\n",
    "Analogue to the SHHS Dataset, we will save the data to our SleepDataManager and transform it into windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant_keys = [\"file_name\", \"RRI\", \"RRI_frequency\", \"MAD\", \"MAD_frequency\", \"SLP\"]\n",
    "# results_generator = load_from_pickle(\"Processed_GIF/GIF_Results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gif_dataset = \"Raw_Data/GIF_dataset.h5\"\n",
    "\n",
    "gif_dataset = h5py.File(path_to_gif_dataset, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering Data from .h5 into .pkl file using SleepDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# initializing the database\n",
    "path_to_save_processed_gif_data = \"Processed_Data/gif_data.pkl\"\n",
    "gif_data_manager = SleepDataManager(file_path = path_to_save_processed_gif_data)\n",
    "\n",
    "# accessing patient ids:\n",
    "patients = list(gif_dataset['stage'].keys()) # type: ignore\n",
    "\n",
    "# check if patient ids are unique:\n",
    "gif_data_manager.check_if_ids_are_unique(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 ['SL003', 'SL005', 'SL006', 'SL008', 'SL009', 'SL010', 'SL012', 'SL013', 'SL014', 'SL015', 'SL017', 'SL018', 'SL019', 'SL020', 'SL021', 'SL022', 'SL024', 'SL026', 'SL028', 'SL029', 'SL030', 'SL031', 'SL033', 'SL035', 'SL036', 'SL038', 'SL039', 'SL041', 'SL042', 'SL043', 'SL044', 'SL045', 'SL046', 'SL047', 'SL048', 'SL049', 'SL050', 'SL051', 'SL052', 'SL053', 'SL054', 'SL056', 'SL058', 'SL059', 'SL060', 'SL062', 'SL063', 'SL064', 'SL065', 'SL067', 'SL068', 'SL069', 'SL070', 'SL071', 'SL072', 'SL074', 'SL077', 'SL078', 'SL080', 'SL081', 'SL082', 'SL084', 'SL086', 'SL092', 'SL093', 'SL094', 'SL095', 'SL097', 'SL099', 'SL102', 'SL103', 'SL104', 'SL106', 'SL107', 'SL108', 'SL109', 'SL110', 'SL112', 'SL113', 'SL115', 'SL117', 'SL118', 'SL119', 'SL120', 'SL121', 'SL122', 'SL123', 'SL124', 'SL125', 'SL127', 'SL128', 'SL129', 'SL130', 'SL131', 'SL134', 'SL135', 'SL136', 'SL137', 'SL139', 'SL140', 'SL142', 'SL143', 'SL144', 'SL146', 'SL147', 'SL148', 'SL149', 'SL150', 'SL152', 'SL153', 'SL154', 'SL155', 'SL156', 'SL158', 'SL160', 'SL161', 'SL162', 'SL163', 'SL164', 'SL167', 'SL168', 'SL169', 'SL170', 'SL171', 'SL172', 'SL175', 'SL177', 'SL180', 'SL181', 'SL182', 'SL183', 'SL184', 'SL185', 'SL187', 'SL188', 'SL189', 'SL190', 'SL191', 'SL192', 'SL194', 'SL195', 'SL196', 'SL197', 'SL198', 'SL200', 'SL201', 'SL206', 'SL212', 'SL213', 'SL215', 'SL220', 'SL222', 'SL223', 'SL224', 'SL225', 'SL226', 'SL230', 'SL231', 'SL232', 'SL233', 'SL234', 'SL235', 'SL238', 'SL239', 'SL241', 'SL242', 'SL243', 'SL244', 'SL251', 'SL253', 'SL254', 'SL256', 'SL258', 'SL259', 'SL260', 'SL261', 'SL262', 'SL263', 'SL264', 'SL265', 'SL266', 'SL267', 'SL270', 'SL271', 'SL272', 'SL273', 'SL274', 'SL275', 'SL276', 'SL277', 'SL278', 'SL279', 'SL280', 'SL281', 'SL282', 'SL283', 'SL284', 'SL285', 'SL287', 'SL288', 'SL289', 'SL291', 'SL292', 'SL295', 'SL296', 'SL297', 'SL298', 'SL299', 'SL300', 'SL301', 'SL302', 'SL303', 'SL304', 'SL306', 'SL307', 'SL308', 'SL309', 'SL310', 'SL311', 'SL312', 'SL313', 'SL314', 'SL317', 'SL318', 'SL319', 'SL320', 'SL321', 'SL323', 'SL324', 'SL325', 'SL326', 'SL327', 'SL329', 'SL330', 'SL331', 'SL334', 'SL335', 'SL337', 'SL338', 'SL339', 'SL340', 'SL343', 'SL345', 'SL346', 'SL347', 'SL350', 'SL351', 'SL352', 'SL353', 'SL354', 'SL355', 'SL356', 'SL357', 'SL358', 'SL360', 'SL361', 'SL362', 'SL363', 'SL364', 'SL366', 'SL367', 'SL368', 'SL369', 'SL370', 'SL371', 'SL372', 'SL373', 'SL374', 'SL375', 'SL376', 'SL377', 'SL378', 'SL379', 'SL381', 'SL383', 'SL385', 'SL387', 'SL388', 'SL390', 'SL391', 'SL393', 'SL394', 'SL395', 'SL396', 'SL398', 'SL400', 'SL401', 'SL402', 'SL403', 'SL404', 'SL405', 'SL407', 'SL409']\n",
      "1\n",
      "4\n",
      "1\n",
      "1439 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3.]\n",
      "172680\n",
      "43170\n"
     ]
    }
   ],
   "source": [
    "print(len(patients), patients)\n",
    "print(gif_dataset[\"stage\"].attrs[\"freq\"])\n",
    "print(gif_dataset[\"rri\"].attrs[\"freq\"])\n",
    "print(gif_dataset[\"mad\"].attrs[\"freq\"])\n",
    "sleep = gif_dataset[\"stage\"][\"SL003\"][:]\n",
    "rri = gif_dataset[\"rri\"][\"SL003\"][:]\n",
    "mad = gif_dataset[\"mad\"][\"SL003\"][:]\n",
    "print(len(sleep), sleep[400:500])\n",
    "print(len(rri))\n",
    "print(len(mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all ID's are unique, you can continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all data from GIF dataset to the gif_data.pkl file\n",
    "for patient_id in patients:\n",
    "    new_datapoint = {\n",
    "        \"ID\": patient_id,\n",
    "        \"RRI\": gif_dataset[\"rri\"][patient_id][:], # type: ignore\n",
    "        \"MAD\": gif_dataset[\"mad\"][patient_id][:], # type: ignore\n",
    "        \"SLP\": gif_dataset[\"stage\"][patient_id][:], # type: ignore\n",
    "        \"RRI_frequency\": gif_dataset[\"rri\"].attrs[\"freq\"], # type: ignore\n",
    "        \"MAD_frequency\": gif_dataset[\"mad\"].attrs[\"freq\"], # type: ignore\n",
    "        \"SLP_frequency\": 1/30, # type: ignore\n",
    "        \"sleep_stage_label\": copy.deepcopy(gif_sleep_stage_label)\n",
    "    }\n",
    "\n",
    "    gif_data_manager.save(new_datapoint, unique_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data to overlapping windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_data_manager.transform_signals_to_windows(\n",
    "    number_windows = 1197, \n",
    "    window_duration_seconds = 120, \n",
    "    overlap_seconds = 90, \n",
    "    priority_order = [0, 1, 2, 3, 5, -1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training-, Validation- and Test- Datasets\n",
    "\n",
    "For easier application we will split our database into main-, training-, validation- and test- files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shhs_data_manager.separate_train_test_validation(\n",
    "    train_size = 0.8, \n",
    "    validation_size = 0.1, \n",
    "    test_size = 0.1, \n",
    "    random_state = None, \n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_data_manager.separate_train_test_validation(\n",
    "    train_size = 0.8, \n",
    "    validation_size = 0.1, \n",
    "    test_size = 0.1, \n",
    "    random_state = None, \n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have 3 additional files in the same directory where our processed data is saved.\n",
    "\n",
    "Each could be accessed separately with another instance of the class SleepDataManager. Note that their functionality\n",
    "is limited, as they are only meant to return (load) data.\n",
    "\n",
    "The data in these files can be reshuffled by calling the above code cell again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders\n",
    "\n",
    "We now want to access our training-, validation- and test- data using a custom dataset class and the\n",
    "dataloader, as it was tought/suggested in the PyTorch Tutorials \n",
    "(Source: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data_shhs = CustomSleepDataset(path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for training with DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
